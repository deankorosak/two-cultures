\documentclass[amsfonts, amssymb, prl, superscriptaddress, notitlepage, twocolumn, nofootinbib]{revtex4-2}

\usepackage{amsmath}    
\usepackage{graphicx}   
\usepackage{verbatim}   
\usepackage{color}      
\usepackage{hyperref}   
%\usepackage{subcaption}
\usepackage[english]{babel}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{subfigure}
\usepackage[autostyle]{csquotes}
%\MakeOuterQuote{"}
\usepackage{float}
\usepackage{textcomp}
\usepackage{xspace}
\usepackage{orcidlink}



\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Cov}{\operatorname{Cov}}
\DeclareMathOperator{\E}{\mathbb{E}} 
\DeclareMathOperator{\Var}{Var}
\newcommand{\bc}[2]{$\beta$#1cell#2}
\newcommand{\lra}[1]{\langle{}#1\rangle}
\newcommand{\Ca}{Ca$^{2+}$\xspace}
\newcommand{\Cac}{[Ca${}^{2+}$]$_{\rm{c}}$\xspace}


\begin{document}

\title{Two cultures}
\author{L.~Kopitar \orcidlink{0000-0002-6647-9988}}
\affiliation{University of Maribor, Slovenia}

\author{N.~Plohl}
\affiliation{University of Maribor, Slovenia}

\author{M.~Tancer Verboten}
\affiliation{University of Maribor, Slovenia}

\author{G.~Štiglic \orcidlink{0000-0002-0183-8679}}
\affiliation{University of Maribor, Slovenia}

\author{R.~Watson \orcidlink{0000-0001-8040-7625}}
\affiliation{Southwest Medical University, China }

\author{D.~Korošak \orcidlink{0000-0003-3818-1233} }
\thanks{Corresponding author:\\dean.korosak@um.si}
\affiliation{University of Maribor, Slovenia}
%\affiliation{University of Maribor, Faculty of Civil Engineering, Transportation Engineering and Architecture, Maribor, Slovenia}
% https://orcid.org/0000-0003-3818-1233




\date{\today}

\begin{abstract}
The evaluation of university performance has traditionally relied heavily on research output, with academic journal publications playing a central role. However, the reliance on publication metrics such as total citations, journal impact factors, and h-indices to assess both institutions and individual academics has been fraught with controversy. Initiatives like DORA and CoARA have emerged to mitigate the potential misuse of these metrics, advocating for a more qualitative approach to research assessment that includes aspects of research culture, inclusivity, and diversity. Our study explores how academic journal publications are utilized across universities and countries, and whether the adherence to declarations such as DORA and CoARA influences this utilization. The analysis, conducted using the OpenAlex API, focused on universities ranked in the CWTS Open Ranking, using the ratio of publications in MDPI versus the Big Five publishers as a measure of publishing habits. Results indicated significant differences in publishing practices, with a clear separation into two distinct scholarly publishing cultures. The MDPI ratio distributions revealed a difference both at the university and country levels, highlighting an increasing gap between new and old EU member states. Furthermore, the study demonstrated a correlation between a university's rank and its publishing culture, as well as between national innovation potential, corruption perception, and publishing practices. We argue that...
\end{abstract}

\maketitle 

\section{Introduction}
One of the mainstays of evaluating the performance of universities is their performance in research, and a major plank of that evaluation is constituted by publication in academic journals. Likewise, the evaluation of individual academics follows similar processes. 
We have previously discussed the controversies involved in using publication in academic journals to evaluate individual academics~\cite{watson2023assessing} and many of those issues apply to the use of publication in academic journals apply to the evaluation of universities. Specifically, the use of publication metrics such as total citations to articles, impact factor of journals and h-indices of individual academics. 
To mitigate the use or inappropriate use of publication metrics there have been initiatives such as DORA (San Francisco Declaration on Research Assessment) and, more specific to European universities, CoARA (Coalition for Advancing Research Assessment, Barcelona declaration). Both of these declarations eschew the use of raw bibliometrics. DORA approaches this by urging signatories to avoid the use of journal impact factors and to consider, for example, narrative CVs, and CoARA provides for more qualitative indicators of research quality, urging signatories to consider aspects of research culture such as inclusivity and diversity. 
Two questions arise. First, how is publication in academic journals used across universities and countries (in Europe/internationally)? Second, is there a difference in the use if publication in academic journals to evaluate research between universities that sign declarations such as DORA and CoARA? 

Towards that end, we used CTWS Open Ranking data for universities listed there making comparisons on the basis of total publications, type of publication and publishers used. In addition, we analysed open access publishing to see if patterns could be established and inferences drawn.

In many scientific fields, research funding affects publication and productivity. Grant funding generally increases publication output and impact, but this depends on the field of study, researcher experience, and funding mechanism. A systematic review of comparative studies found that awarded applicants published 0.14 articles per year more than rejected applicants~\cite{saygitov2018impact}. Recently, detailed grant application data analysis have found larger positive effects of funding on publication outcomes. A multi-year Norwegian research grant study found that recipients publish 5.14 more articles than the control group~\cite{adda2023impact}. The same study found substantial positive effects on publication quality metrics, including an increase in publications weighted by journal influence score and in citation-weighted publications. An analysis of Swiss National Science Foundation grants similarly found that funded researchers publish about one additional peer-reviewed article per year in the three years following funding compared to unsuccessful applicants. These additional publications also tend to be more influential as measured by citation counts ~\cite{ heyard2021value}. Funding appears to affect more than just publication numbers. Funded research has higher citation metrics and altmetrics scores, suggesting that grants improve research quality and dissemination~\cite{heyard2021value}. Importantly, funding affects more than just core project publications. A biomedical research funding study found significant "ripple effects," with even higher increase in publications for papers related to funding, but without principal investigators ~\cite{sattari2022ripple}. This suggests that funding affects research teams and collaborations beyond the funded project. Overall, the evidence indicates that competitive research funding plays an important role in facilitating knowledge creation and dissemination across scientific fields. However, most of the research mentioned above focuses on local or grant funding, while in our study, we aim to capture the trends on a wider scale by comparing the publication trends between different countries or groups of countries.

\section{Methods and results}
OpenAlex~\cite{priem2022openalex} is an open-access platform designed to index scientific publications. It provides access to metadata about scientific papers, journals, authors, and ultimately institutions. The OpenAlex API was utilized for simplified and automatized access to data in the OpenAlex repository. The OpenAlex API is freely available and does not necessitate an API key for utilization, making it fairly easy to use. Due to the rate limits, which are implemented to prevent abuse and ensure fair usage, we had to send requests in 30 second intervals. 

We analyzed publishing data for all universities that were ranked in CTWS Open Ranking~\cite{cwts2024leiden}. For each institution, we fetched its data based on ROR ID~\cite{ROR} and publication year. This dataset was then further processed by considering the publication type and calculating the total number of publications. By aggregating ROR ID, year, and journal type, we derived new features such as the number of publications published with MDPI, Taylor\&Francis, Springer Nature, Wiley, Sage, and Elsevier, the number of retracted publications, the number of open access publications, and the number of gold open access publications. These features can be used to examine various indicators of publishing habits and serve as a starting point for comparing institutions publishing culture. 

We selected MDPI as a representative open access publisher because it is successful, relatively new, widely used and offers journals across almost all subjects as a comparison with legacy journals published by more established publishers. All publishers now offer open access publishing, and established publishers, such as Wiley and Elsevier publish a suite of hybrid journals offering both pay to view and pay to publish alongside a developing suite of open access journals. MDPI, on the other hand, offer only open access journals and compared, for example with Wiley~\cite{wiley} offer lower article processing charges (APCs) and higher rates of acceptance~\cite{fillon2024should}. Rates for MDPI journals are generally kept below \$ 2000~\cite{mdpi_apc}, compared with some hybrid journals charging in the region of \$ 5000 and Nature charging up to nearly \$ 13,000~\cite{nature_publishing_options}.

Here we focus on the ratio, $\rho$, between the number of publications published with MDPI and the Big Five (Springer Nature, Wiley, Elsevier, Taylor\&Francis, Sage) in a given year defined as: 

\begin{equation}
\rho = \frac{N_{\text{MDPI}}}{N_{\text{Big Five}}+N_{\text{MDPI}}}
\end{equation}

where $N_{\text{MDPI}}$ is the number of publications published with MDPI and $N_{\text{Big Five}}$ is the number of publications published with the Big Five publishers.

\begin{figure}
\centering
\includegraphics[width=1.0\linewidth]{Fig01f.png}
\caption{\label{fig:fig1} {\bf Figure title.} (A) MDPI ratio distributions for 2022, university level, difference in gaussian means between 2019 and 2023: 0.116, 0.186, 0.219, 0.196, 0.199. (B) MDPI ratio distributions for 2022, country level, difference in gaussian means between 2019 and 2023: 0.086, 0.139, 0.174, 0.179, 0.232.
}
\end{figure}

In figure 1 we show the MDPI ratio distribution with universities ranked in CWTS Leiden Open Ranking (panel A) for 2022. The distribution is well described by two-gaussian mixture (full line, individual gaussians  are plotted with dashed lines). In panel B of Figure 1 we show the MDPI ratio distribution across countries with universities ranked in CWTS Leiden Open Ranking.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig01af.png}
    \caption{\label{fig:fig2} {\bf Figure title.} MDPI ratio in 2022 for countries with universities ranked in CWTS Leiden Open Ranking. The horizontal line corresponds to minimum of the two-gaussian mixture fit.
    }
    \end{figure}

Figure 2 shows the MDPI ratio in 2022 for countries with universities ranked in CWTS Leiden Open Ranking. The horizontal line corresponds to minimum of the two-gaussian mixture fit.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig02f.png}
    \caption{\label{fig:fig3} {\bf Figure title.} Mean MDPI ratio vs years for EU-13 and EU-14 countries. Using Mann-Wittney U test we found that the differences in mean MDPI ratio between EU-13 and EU-14 countries are statistically significant with $^{**}p<0.01$.
    }
\end{figure}

Figure 3 displays the mean MDPI ratio separately for EU-13 and EU-14 countries, so-called new and old EU member states. The
gap and the increasing trend of the gap over the years in mean MDPI ratio between these two country groups is clearly visible. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig02af.png}
    \caption{\label{fig:fig4} {\bf Figure title.} Mean p-values for Mann-Whitney U test for differences in mean MDPI ratio between EU-13 and EU-14 countries.
    }
\end{figure}

Figure 4 shows the mean p-values for the Mann-Whitney U test for the differences in mean MDPI ratio between EU-13 and EU-14 countries in which 0, 1 or 2 countries are randomly switched between the two groups. The p-values are calculated for 10000 random permutations of countries between the two groups.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig03f.png}
    \caption{\label{fig:fig5} {\bf Figure title.} 
}
\end{figure}
% EU-14 group = [Austria, Belgium, Denmark, Finland, France, Germany, Greece, Ireland, Italy, Luxembourg, Netherlands, Portugal, Spain, Sweden]
% EU-13 group = [Croatia, Cyprus, Czech Republic, Estonia, Hungary, Lithuania, Poland, Romania, Slovakia, Slovenia]

In figure 5, panel A, we display the relationship between the MDPI ratio and the rank of universities included in CWTS Leiden Open Ranking table. The individual data points in the figure are the averages of MDPI ratios of universities in bins each 50 ranks wide. This relationship can be well described by a simple linear relationship between the rank of the university and its scholarly publishing culture. In panel B of figure 3 we show the relationship between the MDPI ratio and the rank of countries of universities included in CWTS Leiden Open Ranking table. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig04f.png}
    \caption{\label{fig:fig6} {\bf Figure title.} Innovation potential, corruption perception and scholarly publishing culture
}
\end{figure}

In figure 6 we show the relationship between innovation potential (EIS), corruption perception (CPI) and the scholarly publishing culture as quantified here through MDPI ratio (panels A and B) on a country level. For clarity only some of countries are indicated with country codes.

\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{Fig05f.png}
    \caption{\label{fig:fig7} {\bf Figure title.} MDPI ratio distributions, CoARA universities  
}
\end{figure}

Figure 7 displays the distribution of MDPI ratio for CoARA universities included in CWTS ranking compared to all CWTS ranked universities. Both distributions are quite similar, exhibiting two-gaussian mixture shape. This puts CoARA group universities in a unique position where one can observe whether in the following years the shift towards more homogeneous publishing practice will happen driven by coalitions tenets.   

\section{Evolution of two cultures in scholarly publishing }
In one study~\cite{baccini2019citation} the authors examine how the introduction of bibliometric evaluations in Italy in 2011 led researchers to change their behavior, focusing more on self-citations and strategic citations to improve their evaluation scores. One way to understand such a shift is to use a game theoretical framework, where the new policy incentivizes researchers to prioritize self-promotion over traditional publication practices. This collective shift in behavior demonstrates how policy changes can significantly influence academic norms, leading to a new equilibrium where citation gaming becomes the dominant strategy to achieve career advancements. 


We showed that the MDPI ratio distribution is well described by two-gaussian mixed distribution which is a weighted sum of two gaussian distributions $P(x) = \omega\mathcal{N}(x|\mu_1, \sigma_1) + (1-\omega)\mathcal{N}(x|\mu_2, \sigma_2)$ peaked around mean values $\mu_1, \mu_2$ for MDPI ratios with widths $\sigma_1, \sigma_2$ for EU-14 and EU-13 countries. Suppose that means and variances evolve with time much slower than the values of the weight $0\ge\omega\le 1$.  Therefore, the shape of $P(x)$ will be mostly determined by the time evolution of $\omega$. The emergence of two cultures in scholarly publishing when $\omega > 0$ or when the second peak with $\mu_2 >\mu_1$ occurs.  

To show how two distinct cultures can emerge from a single culture within the realm of scholarly publishing in the EU, we use a game theory approach. The game involves researchers choosing between two strategies: publishing in established, legacy journals with typically slow reviewing processes (strategy B) or in new, fast-reviewing, open-access journals (strategy A). Initially, most researchers follow strategy B, reflecting the traditional approach. However, an increasing push for open science and the appeal of rapid dissemination create incentives for adopting strategy A. 

\begin{equation}
    u_1 = P(e_1, e_2)R - e_1
\end{equation}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig07.png}
    \caption{\label{fig:fig7} {\bf Figure title.} Game theory model of scholarly publishing culture evolution. Researchers choose between two strategies: publishing in established, legacy journals with typically slow reviewing processes (strategy B) or in new, fast-reviewing, open-access journals (strategy A). 
}
\end{figure}

Researchers payoffs depend on coordination with peers; citation practices, visibility, academic recognition-prestige, cost, speed  




\section{Discussion}
Our findings reveal significant insights into the current state and evolving trends of scholarly publishing practices among universities and EU countries. Using open research information of scholarly publications and university ranking we showed that there is a clear bifurcation in publishing cultures in Europe. 

The separation, evident at both the university and country levels, indicates a growing divergence in publication strategies, influenced by factors such as policy changes and institutional rankings. The increasing gap between EU-13 and EU-14 countries underscores the impact of regional dynamics on academic publishing. Additionally, the correlation between publishing practices and factors like innovation potential and corruption perception suggests that broader socio-economic contexts play a role in shaping research outputs. 



\begin{figure}
    \centering
    \includegraphics[width=.95\linewidth]{Fig06f.png}
    \caption{\label{fig:fig7} {\bf Figure title.} APCs. Data~\cite{kbel_ross-hellauer_2022} and Butler et al. data~\cite{butler2024,haustein2024estimating}.
}
\end{figure}

Figure XX shows the average APCs for different publishers. The data is taken from~\cite{kbel_ross-hellauer_2022} and Butler et al. data~\cite{butler2024,haustein2024estimating} and matched at year 2019. 

mutations: incentives, funding, legislation, open access, APCs, prestige, career advancement, research quality, collaboration, citation practices, visibility, academic recognition, innovation potential, corruption perception, socio-economic contexts, regional dynamics, policy changes, institutional rankings,
Labor law, universities and research assessment systems across EU: north-west vs south-east comparison 
Response of countries to open access/science EU initiative and the NW-SE divide... EU-13 vs EU-14 gap, ERA harmonization
  
\begin{center}
--\,--\,--\,--\,--
\end{center}
\vspace{1mm}
\noindent\textbf{Acknowledgements.} DK received financial support from the Slovenian Research Agency (the research core funding program P3-0396 and the research project no.J7-3156). 

\noindent\textbf{Code and data availability.} The data and the code used in this work is available at \url{https://github.com/deankorosak/two-cultures/}.

\noindent\textbf{Author contributions.} All authors contributed substantially to all aspects of the study.

\noindent\textbf{Conflict of interest.} The authors declare no conflict of interest, financial or otherwise.
 

\bibliography{refs}{}
\bibliographystyle{apsrev4-1}

\end{document}