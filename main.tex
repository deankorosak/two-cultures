\documentclass[amsfonts, amssymb, prl, superscriptaddress, notitlepage, twocolumn, nofootinbib]{revtex4-2}

\usepackage{amsmath}    
\usepackage{graphicx}   
\usepackage{verbatim}   
\usepackage{color}      
\usepackage{hyperref}   
%\usepackage{subcaption}
\usepackage[english]{babel}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{subfigure}
\usepackage[autostyle]{csquotes}
%\MakeOuterQuote{"}
\usepackage{float}
\usepackage{textcomp}
\usepackage{xspace}
\usepackage{orcidlink}



\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Cov}{\operatorname{Cov}}
\DeclareMathOperator{\E}{\mathbb{E}} 
\DeclareMathOperator{\Var}{Var}
\newcommand{\bc}[2]{$\beta$#1cell#2}
\newcommand{\lra}[1]{\langle{}#1\rangle}
\newcommand{\Ca}{Ca$^{2+}$\xspace}
\newcommand{\Cac}{[Ca${}^{2+}$]$_{\rm{c}}$\xspace}


\begin{document}

\title{Two cultures}
\author{L.~Kopitar \orcidlink{0000-0002-6647-9988}}
\affiliation{University of Maribor, Faculty of Health Sciences, Slovenia}

\author{N.~Plohl}
\affiliation{University of Maribor, Faculty of Arts, Slovenia}

\author{M.~Tancer Verboten}
\affiliation{University of Maribor, Faculty of Law, Slovenia}
\affiliation{University of Maribor, Faculty of Chemistry and Chemical Engineering, Slovenia}


\author{G.~Štiglic \orcidlink{0000-0002-0183-8679}}
\affiliation{University of Maribor, Faculty of Health Sciences, Slovenia}

\author{R.~Watson \orcidlink{0000-0001-8040-7625}}
\affiliation{Southwest Medical University, China }

\author{D.~Korošak \orcidlink{0000-0003-3818-1233} }
\thanks{Corresponding author:\\dean.korosak@um.si}
\affiliation{University of Maribor, Faculty of Medicine, Slovenia}
\affiliation{University of Maribor, Faculty of Civil Engineering, Transportation Engineering and Architecture, Maribor, Slovenia}
% https://orcid.org/0000-0003-3818-1233




\date{\today}

\begin{abstract}
The evaluation of university performance has traditionally relied heavily on research output, with academic journal publications playing a central role. However, the reliance on publication metrics such as total citations, journal impact factors, and h-indices to assess both institutions and individual academics has been fraught with controversy. Initiatives like DORA and CoARA have emerged to mitigate the potential misuse of these metrics, advocating for a more qualitative approach to research assessment that includes aspects of research culture, inclusivity, and diversity. Our study explores how academic journal publications are utilized across universities and countries, and whether the adherence to declarations such as DORA and CoARA influences this utilization. The analysis, conducted using the OpenAlex API, focused on universities ranked in the CWTS Open Ranking, using the ratio of publications in MDPI versus the Big Five publishers as a measure of publishing habits. Results indicated significant differences in publishing practices, with a clear separation into two distinct scholarly publishing cultures. The MDPI ratio distributions revealed a difference both at the university and country levels, highlighting an increasing gap between new and old EU member states. Furthermore, the study demonstrated a correlation between a university's rank and its publishing culture, as well as between national innovation potential, corruption perception, and publishing practices. We argue that...
\end{abstract}

\maketitle 

\section{Introduction}
One of the mainstays of evaluating the performance of universities is their performance in research, and a major plank of that evaluation is constituted by publication in academic journals. Likewise, the evaluation of individual academics follows similar processes. 
We have previously discussed the controversies involved in using publication in academic journals to evaluate individual academics~\cite{watson2023assessing} and many of those issues apply to the use of publication in academic journals apply to the evaluation of universities. Specifically, the use of publication metrics such as total citations to articles, impact factor of journals and h-indices of individual academics. 
To mitigate the use or inappropriate use of publication metrics there have been initiatives such as DORA (San Francisco Declaration on Research Assessment) and, more specific to European universities, CoARA (Coalition for Advancing Research Assessment, Barcelona declaration). Both of these declarations eschew the use of raw bibliometrics. DORA approaches this by urging signatories to avoid the use of journal impact factors and to consider, for example, narrative CVs, and CoARA provides for more qualitative indicators of research quality, urging signatories to consider aspects of research culture such as inclusivity and diversity. 
Two questions arise. First, how is publication in academic journals used across universities and countries (in Europe/internationally)? Second, is there a difference in the use if publication in academic journals to evaluate research between universities that sign declarations such as DORA and CoARA? 

Towards that end, we used CTWS Open Ranking data for universities listed there making comparisons on the basis of total publications, type of publication and publishers used. In addition, we analysed open access publishing to see if patterns could be established and inferences drawn.

In many scientific fields, research funding affects publication and productivity. Grant funding generally increases publication output and impact, but this depends on the field of study, researcher experience, and funding mechanism. A systematic review of comparative studies found that awarded applicants published 0.14 articles per year more than rejected applicants~\cite{saygitov2018impact}. Recently, detailed grant application data analysis have found larger positive effects of funding on publication outcomes. A multi-year Norwegian research grant study found that recipients publish 5.14 more articles than the control group~\cite{adda2023impact}. The same study found substantial positive effects on publication quality metrics, including an increase in publications weighted by journal influence score and in citation-weighted publications. An analysis of Swiss National Science Foundation grants similarly found that funded researchers publish about one additional peer-reviewed article per year in the three years following funding compared to unsuccessful applicants. These additional publications also tend to be more influential as measured by citation counts ~\cite{ heyard2021value}. Funding appears to affect more than just publication numbers. Funded research has higher citation metrics and altmetrics scores, suggesting that grants improve research quality and dissemination~\cite{heyard2021value}. Importantly, funding affects more than just core project publications. A biomedical research funding study found significant "ripple effects," with even higher increase in publications for papers related to funding, but without principal investigators ~\cite{sattari2022ripple}. This suggests that funding affects research teams and collaborations beyond the funded project. Overall, the evidence indicates that competitive research funding plays an important role in facilitating knowledge creation and dissemination across scientific fields. However, most of the research mentioned above focuses on local or grant funding, while in our study, we aim to capture the trends on a wider scale by comparing the publication trends between different countries or groups of countries.

\begin{comment}
An essential precondition for a successful operation of universities in the complex circumstances of the changing global environment is their ability and opportunity to make independent decisions. It's problematic, if the universities are being completely under state regulation.1 The rectors of European universities gathered in Bologna on the occasion of the nine hundredth anniversary of the oldest university in Europe, and among the fundamental principles for the operation of universities, determined the autonomy of the institution, which must meet the needs of the environment, and its research must be independent of political authorities and economic forces.

European universities are thus guaranteed a special status, they have the so-called i. university autonomy, which is differently defined and legally regulated in individual countries. In order to monitor the development of the higher education space over the elements of university autonomy in the EU, in 2007 EUA started collecting data on university autonomy in the four areas defined by the Lisbon Declaration (hereafter EUA, 2007).2

Staffing autonomy is one of the areas of university autonomy and means the authority of the university to independently make decisions in the field of personnel. The status of employees is also important when universities make decisions, especially whether teaching staff have the status of civil servants.

Universities are usually compared to each other and ranked in different rankings based on their performance, especially in the field of research. Universities also compete for predetermined and limited research funds on the basis of various tenders in the institutional or European level.

Institutional autonomy within the EU is recognized as a direction for the development of European universities and as a condition for the creation and enjoyment of true academic freedom and means the degree of self-government necessary to make effective decisions about academic work, criteria, management and related activities, taking into account the responsibility they have institutions to the public, especially in relation to public funding, respect for academic freedom.3

With their internal rules, universities naturally also influence the behavior of individual researchers when publishing their scientific results.  
\end{comment}

\section{Methods and results}
OpenAlex~\cite{priem2022openalex} is an open-access platform designed to index scientific publications. It provides access to metadata about scientific papers, journals, authors, and ultimately institutions. The OpenAlex API was utilized for simplified and automatized access to data in the OpenAlex repository. The OpenAlex API is freely available and does not necessitate an API key for utilization, making it fairly easy to use. Due to the rate limits, which are implemented to prevent abuse and ensure fair usage, we had to send requests in 30 second intervals. 

We analyzed publishing data for all universities that were ranked in CTWS Open Ranking~\cite{cwts2024leiden}. For each institution, we fetched its data based on ROR ID~\cite{ROR} and publication year. This dataset was then further processed by considering the publication type and calculating the total number of publications. By aggregating ROR ID, year, and journal type, we derived new features such as the number of publications published with MDPI, Taylor\&Francis, Springer Nature, Wiley, Sage, and Elsevier, the number of retracted publications, the number of open access publications, and the number of gold open access publications. These features can be used to examine various indicators of publishing habits and serve as a starting point for comparing institutions publishing culture. 

We selected MDPI as a representative open access publisher because it is successful, relatively new, widely used and offers journals across almost all subjects as a comparison with legacy journals published by more established publishers. All publishers now offer open access publishing, and established publishers, such as Wiley and Elsevier publish a suite of hybrid journals offering both pay to view and pay to publish alongside a developing suite of open access journals. MDPI, on the other hand, offer only open access journals and compared, for example with Wiley~\cite{wiley} offer lower article processing charges (APCs) and higher rates of acceptance~\cite{fillon2024should}. Rates for MDPI journals are generally kept below \$ 2000~\cite{mdpi_apc}, compared with some hybrid journals charging in the region of \$ 5000 and Nature charging up to nearly \$ 13,000~\cite{nature_publishing_options}.

Here we focus on the ratio, $\rho$, between the number of publications published with MDPI and the Big Five (Springer Nature, Wiley, Elsevier, Taylor\&Francis, Sage) in a given year defined as: 

\begin{equation}
\rho = \frac{N_{\text{MDPI}}}{N_{\text{Big Five}}+N_{\text{MDPI}}}
\end{equation}

where $N_{\text{MDPI}}$ is the number of publications published with MDPI and $N_{\text{Big Five}}$ is the number of publications published with the Big Five publishers.

\begin{figure}
\centering
\includegraphics[width=1.0\linewidth]{Fig01f.png}
\caption{\label{fig:fig1} {\bf Figure title.} (A) MDPI ratio distribution for 2022 at the university level, Full line shows two-gaussian mixture fit, individual gaussians are plotted with dashed lines. (B) MDPI ratio distributions for 2022 at the country level.
}
\end{figure}

In figure 1 we show the MDPI ratio distribution with universities ranked in CWTS Leiden Open Ranking (panel A) for 2022. The distribution is well described by two-gaussian mixture $P(x) = \omega\mathcal{N}(x|\mu_1, \sigma_1) + (1-\omega)\mathcal{N}(x|\mu_2, \sigma_2)$ peaked around mean values $\mu_1, \mu_2$ for MDPI ratios with widths $\sigma_1, \sigma_2$. $\omega$ and $1-\omega$ are the weights of each gaussian peak in the mixture distribution. In panel B of Figure 1 we show the MDPI ratio distribution across countries with universities ranked in CWTS Leiden Open Ranking. The difference $\mu_2-mu_1$ in gaussian means is increasing with time between 2019 and 2023 as: 0.116, 0.186, 0.219, 0.196, 0.199, at the university level, and as: 0.086, 0.139, 0.174, 0.179, 0.232 at the country level. In both cases the separation between the two groups is increasing over time. 



\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig01af.png}
    \caption{\label{fig:fig2} {\bf Figure title.} MDPI ratio in 2022 for countries with universities ranked in CWTS Leiden Open Ranking. The thich horizontal line corresponds to the minimum of the two-gaussian mixture fit. The dotted lines are the means $\mu_1$ and $\mu_2$ of the two gaussians and the shaded bands are the widths $\sigma_1$ and $\sigma_2$.
    }
    \end{figure}

Figure 2 shows the MDPI ratio in 2022 for countries with universities ranked in CWTS Leiden Open Ranking. The thick horizontal line corresponds to minimum of the two-gaussian mixture fit and denotes the approximate separation of countries into two groups. The dotted lines are the means $\mu_1$ and $\mu_2$ of fitted two-gaussian mixed model and the shaded bands are the corresponding widths $\sigma_1$ and $\sigma_2$ of the two peaks. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig02f.png}
    \caption{\label{fig:fig3} {\bf Figure title.} Mean MDPI ratio vs years for EU-13 and EU-14 countries. Using Mann-Wittney U test we found that the differences in mean MDPI ratio between EU-13 and EU-14 countries are statistically significant with $p<0.01$.
    }
\end{figure}

Figure 3 displays the mean MDPI ratio separately for EU-13 and EU-14 countries, so-called new and old EU member states. The
gap and the increasing trend of the gap over the years in mean MDPI ratio between these two country groups is clearly visible. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig02af.png}
    \caption{\label{fig:fig4} {\bf Figure title.} Mean p-values for Mann-Whitney U test for differences in mean MDPI ratio between EU-13 and EU-14 countries.
    }
\end{figure}

Figure 4 shows the mean p-values for the Mann-Whitney U test for the differences in mean MDPI ratio between EU-13 and EU-14 countries in which 0, 1 or 2 countries are randomly switched between the two groups. The p-values are calculated for 10000 random permutations of countries between the two groups.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig03f.png}
    \caption{\label{fig:fig5} {\bf Figure title.} 
}
\end{figure}
% EU-14 group = [Austria, Belgium, Denmark, Finland, France, Germany, Greece, Ireland, Italy, Luxembourg, Netherlands, Portugal, Spain, Sweden]
% EU-13 group = [Croatia, Cyprus, Czech Republic, Estonia, Hungary, Lithuania, Poland, Romania, Slovakia, Slovenia]

In figure 5, panel A, we display the relationship between the MDPI ratio and the rank of universities included in CWTS Leiden Open Ranking table. The individual data points in the figure are the averages of MDPI ratios of universities in bins each 50 ranks wide. This relationship can be well described by a simple linear relationship between the rank of the university and its scholarly publishing culture. In panel B of figure 3 we show the relationship between the MDPI ratio and the rank of countries of universities included in CWTS Leiden Open Ranking table. 

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig04f.png}
    \caption{\label{fig:fig6} {\bf Figure title.} Innovation potential, corruption perception and scholarly publishing culture
}
\end{figure}

In figure 6 we show the relationship between innovation potential (EIS), corruption perception (CPI) and the scholarly publishing culture as quantified here through MDPI ratio (panels A and B) on a country level. For clarity only some of countries are indicated with country codes.
% correlation transitivity

\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{Fig05f.png}
    \caption{\label{fig:fig7} {\bf Figure title.} MDPI ratio distributions, CoARA universities  
}
\end{figure}

Figure 7 displays the distribution of MDPI ratio for CoARA universities included in CWTS ranking compared to all CWTS ranked universities. Both distributions are quite similar, exhibiting two-gaussian mixture shape. This puts CoARA group universities in a unique position where one can observe whether in the following years the shift towards more homogeneous publishing practice will happen driven by coalitions tenets.   

\section{Evolution of two cultures in scholarly publishing }
In one study~\cite{baccini2019citation} the authors examine how the introduction of bibliometric evaluations in Italy in 2011 led researchers to change their behavior, focusing more on self-citations and strategic citations to improve their evaluation scores. One way to understand such a shift is to use a game theoretical framework, where the new policy incentivizes researchers to prioritize self-promotion over traditional publication practices. This collective shift in behavior demonstrates how policy changes can significantly influence academic norms, leading to a new equilibrium where citation gaming becomes the dominant strategy to achieve career advancements. 

We showed that the MDPI ratio distribution in case of universities and countries is well described by two-gaussian mixed distribution which is a weighted sum of two gaussian distributions. Suppose that means and variances evolve with time much slower than the values of the weight $0\ge\omega\le 1$.  Therefore, the shape of $P(x)$ will be mostly determined by the time evolution of $\omega$. The emergence of two cultures in scholarly publishing when $\omega > 0$ or when the second peak with $\mu_2 >\mu_1$ occurs.  

To show how two distinct cultures can emerge from a single culture within the realm of scholarly publishing in the EU, we use a game theory approach. The game involves researchers choosing between two strategies: publishing in established, legacy journals with typically slow reviewing processes (strategy B) or in new, fast-reviewing, open-access journals (strategy A). Initially, most researchers follow strategy B, reflecting the traditional approach. However, an increasing push for open science and the appeal of rapid dissemination create incentives for adopting strategy A. 

\begin{equation}
    u_1 = P(e_1, e_2)R - e_1
\end{equation}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{Fig07.png}
    \caption{\label{fig:fig7} {\bf Figure title.} Game theory model of scholarly publishing culture evolution. Researchers choose between two strategies: publishing in established, legacy journals with typically slow reviewing processes (strategy B) or in new, fast-reviewing, open-access journals (strategy A). 
}
\end{figure}

Researchers payoffs depend on coordination with peers; citation practices, visibility, academic recognition-prestige, cost, speed  




\section{Discussion}
Our findings reveal significant insights into the current state and evolving trends of scholarly publishing practices among universities and EU countries. Using open research information of scholarly publications and university ranking we showed that there is a clear bifurcation in publishing cultures in Europe. 

The separation, evident at both the university and country levels, indicates a growing divergence in publication strategies, influenced by factors such as policy changes and institutional rankings. The increasing gap between EU-13 and EU-14 countries underscores the impact of regional dynamics on academic publishing. Additionally, the correlation between publishing practices and factors like innovation potential and corruption perception suggests that broader socio-economic contexts play a role in shaping research outputs. 

The tendency of researchers from EU-13 countries and lower-ranked institutions to publish more in open-access MDPI journals, which provide faster turnaround and are often perceived as less stringent, may be explained in several ways. As publishing behavior is generally the result of a reasoned process, our findings can be interpreted through the lens of the Theory of Planned Behavior~\cite{ajzen1991}, which recognizes the critical role of individuals ability (i.e., perceived behavioral control) and motivation (i.e., intentions, which are heavily influenced by subjective norms and attitudes). While this theory has not yet been studied in the context of explaining researchers’ decision to publish in MDPI over more traditional journals, Moksness and colleagues~\cite{moksness2020} have used it to explain intentions to publish in open-access journals.

First, in relation to perceived behavioral control, researchers from EU-13 and lower-ranked countries may perceive important internal and external barriers to publishing in traditional, legacy journals, such as resource constraints (including financial aspects), fewer international collaboration opportunities, language barriers, and less prestigious institutional affiliations. In fact, recent research suggests that some of these barriers objectively exist; for example, a recent study by Sverdlichenko and colleagues~\cite{sverdlichenko2022} revealed that journal editors may be influenced by author institutional affiliations when deciding whether a manuscript should be sent out for peer review. Second, regarding subjective norms, academics working in EU-13 and lower-ranked countries may feel a stronger social pressure to publish frequently, potentially driven by institutional policies that still reward the quantity (instead of quality) of publications. This may lead to a snowball effect, with early adopters of such practices imposing pressure on others to do the same to remain competitive in their academic environment. Over time, publishing in MDPI over legacy journals can become completely normalized or even desirable in certain academic environments. The important role of social norms, as opposed to solely top-down regulations, in determining researchers publication choices has been previously discussed by other authors (e.g., Migheli and Ramello~\cite{migheli2013}). Lastly, several aspects may contribute to more favorable attitudes towards MDPI in EU-13 and lower-ranked countries. For example, they may believe that publishing in MDPI will help them achieve their academic goals, such as career advancement, quicker, or increase their visibility (due to the open-access nature of these journals).

We also found that researchers from countries with higher corruption perception are more likely to publish in MDPI over the Big Five journals. While this relationship has not yet been investigated in other countries, some parallels can be drawn from the broader literature on the characteristics of individuals who live in countries perceived as highly corrupt. For example, it is well-known that perceptions of corruption are associated with lower institutional trust~\cite{hakhverdian2012}, lower meritocratic ideology~\cite{tan2017}, and adaptive behaviors, whereby societal levels of corruption result in norm and rule violations on the individual level~\cite{kobis2018}. In the specific context of scholarly publishing, researchers may distrust the fairness of the peer-review processes and traditional publishing practices and merits in general. Moreover, environments with high corruption may sometimes be characterized by uncertain career advancement procedures and less transparent and equitable funding, motivating researchers to publish quickly to bolster their CVs and improve their chances in these ambiguous circumstances. 






\begin{figure}
    \centering
    \includegraphics[width=.95\linewidth]{Fig06f.png}
    \caption{\label{fig:fig7} {\bf Figure title.} APCs. Data~\cite{kbel_ross-hellauer_2022} and Butler et al. data~\cite{butler2024,haustein2024estimating}.
}
\end{figure}

Figure XX shows the average APCs for different publishers. The data is taken from~\cite{kbel_ross-hellauer_2022} and Butler et al. data~\cite{butler2024,haustein2024estimating} and matched at year 2019. 

Our findings raise concerns about the potential inequalities in scholarly publishing across Europe. The preference for MDPI publications in EU-13 countries and lower-ranked universities may be influenced by factors such as publication speed and perceived ease of acceptance but could also indicate various challenges faced by researchers in these environments, such as fewer resources available for research and systemic issues that push researchers towards certain publication outlets. In line with this, governments and institutions in EU-13 countries should continue enhancing their support for research activities (e.g., transparent funding procedures, budgets for article processing charges) and empowering academics with better infrastructure, mentoring, and collaboration options. Moreover, extensive efforts should be dedicated to promoting transparent and fair evaluation metrics that go beyond the mere quantity of publications. 

mutations: incentives, funding, legislation, open access, APCs, prestige, career advancement, research quality, collaboration, citation practices, visibility, academic recognition, innovation potential, corruption perception, socio-economic contexts, regional dynamics, policy changes, institutional rankings,
Labor law, universities and research assessment systems across EU: north-west vs south-east comparison 
Response of countries to open access/science EU initiative and the NW-SE divide... EU-13 vs EU-14 gap, ERA harmonization
  
\begin{center}
--\,--\,--\,--\,--
\end{center}
\vspace{1mm}
\noindent\textbf{Acknowledgements.} DK received financial support from the Slovenian Research Agency (the research core funding program P3-0396 and the research project no.J7-3156). 

\noindent\textbf{Code and data availability.} The data and the code used in this work is available at \url{https://github.com/deankorosak/two-cultures/}.

\noindent\textbf{Author contributions.} All authors contributed substantially to all aspects of the study.

\noindent\textbf{Conflict of interest.} The authors declare no conflict of interest, financial or otherwise.
 

\bibliography{refs}{}
\bibliographystyle{apsrev4-1}

\end{document}